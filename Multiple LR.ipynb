{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np # for maths\n",
    "import matplotlib.pyplot as plt   #for visuals\n",
    "import pandas as pd  #for handling data sets\n",
    "from sklearn.preprocessing import Imputer  #to take care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Vishnu/Downloads/ML/Multiple_Linear_Regression/50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "datac = data.copy()\n",
    "#independent variable\n",
    "#X = datac.drop('Salary',axis=1)\n",
    "X= data.iloc[:,:-1].values\n",
    "Y= data.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "#label encoder to change text to numbers. We cant use one hot encoder directly\n",
    "\n",
    "#label_encoder_X = LabelEncoder()\n",
    "#X[:,3]=label_encoder_X.fit_transform(X[:,3])\n",
    "#create dummy variables\n",
    "#onehotencoder = OneHotEncoder(categorical_features=[3]) #specifying which column we need to encode\n",
    "#X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "#New method\n",
    "from sklearn.compose import ColumnTransformer \n",
    "ct = ColumnTransformer([(\"Onehot\", OneHotEncoder(categories='auto'),[3])], remainder=\"passthrough\") # The last arg ([0]) is the list of columns you want to transform in this step\n",
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoiding dummy variable trap\n",
    "\n",
    "X=X[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Multi Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting test results\n",
    "Y_pred=regressor.predict(X_test)\n",
    "\n",
    "#Y_test = real profits (compare the Y_pred and Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([103015.20159796, 132582.27760815, 132447.73845175,  71976.09851258,\n",
       "        178537.48221056, 116161.24230166,  67851.69209676,  98791.73374687,\n",
       "        113969.43533013, 167921.06569551]),\n",
       " array([[0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "        [0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "        [1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "        [0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "        [1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "        [0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "        [0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "        [1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "        [0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "        [0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "        [1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "        [0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "        [1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "        [0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "        [1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "        [0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "        [0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "        [0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "        [1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "        [0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "        [0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "        [0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "        [1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "        [1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "        [0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "        [0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "        [1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "        [0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "        [1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "        [0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "        [1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "        [0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "        [0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "        [1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "        [0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "        [0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "        [1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "        [0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "        [0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "        [0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "        [0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "        [1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "        [0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "        [0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "        [0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "        [0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "        [1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "        [0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "        [0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "        [0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward elimination\n",
    "import statsmodels.api as sm\n",
    "# for statsmodels, we need to include B0 coefficient\n",
    "\n",
    "# Y = B0 + B1X1 + B2X2 ... so coeff of B0 =1 which is not accounted in the statsmodels ( unline LinearRegression model)\n",
    "\n",
    "#X = np.append(arr = X, values = np.ones((50,1)).astype(int),axis=1)#axis=1 columns and axis=0 is r#ows\n",
    "\n",
    "X = np.append(arr = np.ones((50,1)).astype(int), values = X,axis=1) # so that the ones are added at the beginning but the logic is mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [1, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [1, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [1, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [1, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [1, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [1, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [1, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [1, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [1, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [1, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [1, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [1, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [1, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [1, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [1, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [1, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [1, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [1, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [1, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [1, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [1, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [1, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [1, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [1, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [1, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [1, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [1, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [1, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [1, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [1, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [1, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [1, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [1, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 16 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:52:18</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Mon, 16 Sep 2019   Prob (F-statistic):           1.34e-27\n",
       "Time:                        10:52:18   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_opt = will contain only the statistically significant variables\n",
    "\n",
    "X_opt = X[:,[0,1,2,3,4,5]]\n",
    "X_opt =  X_opt.astype(float)   #Y.astype(float)\n",
    "#X and Y needs to be float\n",
    "\n",
    "#new library so new fit should be required\n",
    "regressorOLS = sm.OLS(endog = Y, exog = X_opt).fit() #endog - dependent variable , exog - independent variable\n",
    "regressorOLS.summary()\n",
    "\n",
    "# elimination is carried out in steps as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 16 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:52:25</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Mon, 16 Sep 2019   Prob (F-statistic):           4.53e-30\n",
       "Time:                        10:52:25   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,3,4,5]]\n",
    "X_opt =  X_opt.astype(float)   #Y.astype(float)\n",
    "#X and Y needs to be float\n",
    "\n",
    "#new library so new fit should be required\n",
    "regressorOLS = sm.OLS(endog = Y, exog = X_opt).fit() #endog - dependent variable , exog - independent variable\n",
    "regressorOLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 16 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:53:12</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Mon, 16 Sep 2019   Prob (F-statistic):           2.16e-31\n",
       "Time:                        10:53:12   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,3,5]]\n",
    "X_opt =  X_opt.astype(float)   #Y.astype(float)\n",
    "#X and Y needs to be float\n",
    "\n",
    "#new library so new fit should be required\n",
    "regressorOLS = sm.OLS(endog = Y, exog = X_opt).fit() #endog - dependent variable , exog - independent variable\n",
    "regressorOLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 16 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:55:02</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Mon, 16 Sep 2019   Prob (F-statistic):           3.50e-32\n",
       "Time:                        10:55:02   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,3]]\n",
    "X_opt =  X_opt.astype(float)   #Y.astype(float)\n",
    "#X and Y needs to be float\n",
    "\n",
    "#new library so new fit should be required\n",
    "regressorOLS = sm.OLS(endog = Y, exog = X_opt).fit() #endog - dependent variable , exog - independent variable\n",
    "regressorOLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic backward elimination with p value only \n",
    "\n",
    "#import statsmodels.api as sm\n",
    "#def backwardElimination(x, sl):\n",
    "#    numVars = len(x[0])\n",
    "#    for i in range(0, numVars):\n",
    "#        regressor_OLS = sm.OLS(y, x).fit()\n",
    "#        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "#        if maxVar > sl:\n",
    "#            for j in range(0, numVars - i):\n",
    "#                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "#                    x = np.delete(x, j, 1)\n",
    "#    regressor_OLS.summary()\n",
    "#    return x\n",
    "# \n",
    "#SL = 0.05\n",
    "#X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "#X_Modeled = backwardElimination(X_opt, SL)\n",
    "#\n",
    "#\n",
    "##with pvalue and R Squared\n",
    "#\n",
    "#import statsmodels.api as sm\n",
    "#def backwardElimination(x, SL):\n",
    "#    numVars = len(x[0])\n",
    "#    temp = np.zeros((50,6)).astype(int)\n",
    "#    for i in range(0, numVars):\n",
    "#        regressor_OLS = sm.OLS(y, x).fit()\n",
    "#        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "#        adjR_before = regressor_OLS.rsquared_adj.astype(float)\n",
    "#        if maxVar > SL:\n",
    "#            for j in range(0, numVars - i):\n",
    "#                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "#                    temp[:,j] = x[:, j]\n",
    "#                    x = np.delete(x, j, 1)\n",
    "#                    tmp_regressor = sm.OLS(y, x).fit()\n",
    "#                    adjR_after = tmp_regressor.rsquared_adj.astype(float)\n",
    "#                    if (adjR_before >= adjR_after):\n",
    "#                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n",
    "#                        x_rollback = np.delete(x_rollback, j, 1)\n",
    "#                        print (regressor_OLS.summary())\n",
    "#                        return x_rollback\n",
    "#                    else:\n",
    "#                        continue\n",
    "#    regressor_OLS.summary()\n",
    "#    return x\n",
    "# \n",
    "#SL = 0.05\n",
    "#X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "#X_Modeled = backwardElimination(X_opt, SL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
